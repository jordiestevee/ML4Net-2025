{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb666402",
   "metadata": {},
   "source": [
    "# Seminar 5 - Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5d87ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79c4139",
   "metadata": {},
   "source": [
    " ## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a044dbc0",
   "metadata": {},
   "source": [
    "- We load the datasets for **10 clients**.\n",
    "- Each client has:\n",
    "    - `client_{i}_features.csv`: Wi-Fi CSI measurements (270 features per sample).\n",
    "    - `client_{i}_labels.csv`: Corresponding pose labels (integers from 1 to 12).\n",
    "- **Test Data**:\n",
    "  - A separate test set:\n",
    "    - `test_features.csv` and `test_labels.csv` containing **500 samples**.\n",
    "\n",
    "The CSI data represent Wi-Fi signal reflections when subjects perform different poses, collected for human pose estimation tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9c453e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 270)\n",
      "(64,)\n",
      "(500, 270)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'dataset_Seminar5'\n",
    "num_clients = 10\n",
    "client_data = {}\n",
    "\n",
    "# Load each client’s training data\n",
    "for i in range(1, num_clients + 1):\n",
    "    X_path = os.path.join(data_dir, f'client_datasets/client_{i}_features.csv')\n",
    "    y_path = os.path.join(data_dir, f'client_datasets/client_{i}_labels.csv')\n",
    "    \n",
    "    X = pd.read_csv(X_path, header=None).values  # shape: (num_samples, 270)\n",
    "    y = pd.read_csv(y_path, header=None).values.flatten()  # shape: (num_samples,)\n",
    "    \n",
    "    client_data[i] = {'X': X, 'y': y}\n",
    "\n",
    "# Load test data\n",
    "X_test = pd.read_csv(os.path.join(data_dir, 'test_features.csv'), header=None).values\n",
    "y_test = pd.read_csv(os.path.join(data_dir, 'test_labels.csv'), header=None).values.flatten()\n",
    "\n",
    "print(X.shape)  # shape: (num_samples, 270)\n",
    "print(y.shape)  # shape: (num_samples,)\n",
    "print(X_test.shape)  # shape: (num_samples, 270)\n",
    "print(y_test.shape)  # shape: (num_samples,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759472ee",
   "metadata": {},
   "source": [
    "We will adjust test labels from 0-11 instead of 1-12 for training purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b388d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for client_id in client_data:\n",
    "    client_data[client_id]['y'] -= 1  # Now ranges 0-11\n",
    "\n",
    "y_test -= 1  # Also adjust test labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b0c94",
   "metadata": {},
   "source": [
    "We tried training with different models to see which one fits the most:\n",
    "### `PoseClassifierFC` (Fully Connected Network)\n",
    "- **Type**: Simple Feedforward Neural Network (MLP).\n",
    "- **Architecture**:\n",
    "  - Input: 270 features (flattened CSI data).\n",
    "  - Two hidden layers:\n",
    "    - `Linear(270 → 128)`, `ReLU`, `Dropout(0.3)`.\n",
    "    - `Linear(128 → 64)`, `ReLU`.\n",
    "  - Output layer: `Linear(64 → 12 classes)`.\n",
    "---\n",
    "\n",
    "### `ResSim` (Simplified Residual CNN)\n",
    "- **Type**: Lightweight ResNet-style Convolutional Neural Network.\n",
    "- **Architecture**:\n",
    "  - Input reshaped to (3 channels × 30 × 3 matrix).\n",
    "  - **Two residual blocks**:\n",
    "    - `Conv → ReLU → Conv` + Skip Connection → `ReLU → MaxPool`.\n",
    "  - Flatten the output.\n",
    "  - Fully Connected layer for classification.\n",
    "---\n",
    "\n",
    "### `PoseClassifierCNN` (Standard CNN)\n",
    "- **Type**: Regular Convolutional Neural Network.\n",
    "- **Architecture**:\n",
    "  - Input reshaped to (3 × 30 × 3).\n",
    "  - Two convolutional blocks:\n",
    "    - `Conv → ReLU → BatchNorm → MaxPool`.\n",
    "  - Flatten the output.\n",
    "  - Fully Connected layer → Dropout → Final classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4d875c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseClassifierFC(nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(PoseClassifierFC, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(270, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "efedb4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResSim(nn.Module):\n",
    "    \"\"\"\n",
    "    A simplified ResNet-style network with residual connections and sequential blocks.\n",
    "    \n",
    "    Adapted for CSI input (flattened to 3x30x3).\n",
    "\n",
    "    Architecture:\n",
    "        - Two residual blocks: Conv → ReLU → Conv + skip\n",
    "        - Each followed by MaxPool\n",
    "        - Fully connected classifier\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): Number of output classes.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=12): # 12 different pose classes\n",
    "        super(ResSim, self).__init__()\n",
    "\n",
    "        # Block 1\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.shortcut1 = nn.Conv2d(3, 64, kernel_size=1)  # aligns input channels\n",
    "\n",
    "        # Block 2\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 1)\n",
    "        self.fc = nn.Linear(64 * 7 * 4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3, 30, 3)  # reshape input vector (270,) → (3, 30, 3)\n",
    "\n",
    "        # First residual connection\n",
    "        residual = self.shortcut1(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.relu(x + residual)\n",
    "        x = self.pool(x) # (64, 15, 3)\n",
    "\n",
    "        # Second residual connection (no need for shortcut: same shape)\n",
    "        residual = x\n",
    "        x = self.block2(x)\n",
    "        x = self.relu(x + residual)\n",
    "        x = self.pool(x) # (64, 7, 3)\n",
    "\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "512118c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PoseClassifierCNN(nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(PoseClassifierCNN, self).__init__()\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),  # (3, 30, 3) → (16, 30, 3)\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),  # (16, 15, 3)\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),  # (32, 15, 3)\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))  # (32, 7, 3)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),                    # (32 * 7 * 3)\n",
    "            nn.Linear(32 * 7 * 3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)     # output logits for 12 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input from (batch_size, 270) → (batch_size, 3, 30, 3)\n",
    "        x = x.view(-1, 3, 30, 3)  # match channel-first format\n",
    "        x = self.cnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a7416b",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "`eval_model` Function:\n",
    "\n",
    "Evaluates a model’s accuracy:\n",
    "\n",
    "- **Set eval mode**: Disables layers like dropout.\n",
    "- **Convert** inputs to tensors.\n",
    "- **Predict** class labels (`argmax` over logits).\n",
    "- **Compute accuracy**: Percentage of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ddcd13bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, X, y):\n",
    "    model.eval()  # Set model to evaluation mode \n",
    "    \n",
    "    # Convert input features and labels to PyTorch tensors\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)  # Features: float32\n",
    "    y_tensor = torch.tensor(y, dtype=torch.long)     # Labels: int64 (long)\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation (saves memory and speeds up evaluation)\n",
    "        logits = model(X_tensor)     # Forward pass: compute raw scores (logits)\n",
    "        preds = torch.argmax(logits, dim=1)  # Get class with highest score (predicted label)\n",
    "        accuracy = ((preds == y_tensor).float().mean().item()) * 100  # Compute accuracy as percentage\n",
    "    \n",
    "    return accuracy  # Return accuracy %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38404eb",
   "metadata": {},
   "source": [
    "`eval_loss`\n",
    "- **Evaluates loss** for a model on given data.\n",
    "- **No gradient** computation (`torch.no_grad()`).\n",
    "- Uses the provided **loss criterion** (e.g., CrossEntropy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "db3b88c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loss(model, X, y, criterion):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)  # Features tensor\n",
    "    y_tensor = torch.tensor(y, dtype=torch.long)     # Labels tensor\n",
    "    with torch.no_grad():  # No gradient computation\n",
    "        logits = model(X_tensor)      # Forward pass\n",
    "        loss = criterion(logits, y_tensor)  # Compute loss\n",
    "    return loss.item()  # Return loss value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ed6182",
   "metadata": {},
   "source": [
    "`weighted_train_loss`\n",
    "- **Purpose**: Compute the weighted average loss across selected clients.\n",
    "- For each client:\n",
    "  - Load global model weights.\n",
    "  - Evaluate local loss.\n",
    "- **Weight** each client's loss by its number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3f971da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_train_loss(model_class, global_state, selected_clients, client_data, criterion):\n",
    "    train_losses = []\n",
    "    weights = []\n",
    "    \n",
    "    for k in selected_clients:\n",
    "        model = model_class(num_classes=12)          # Initialize model\n",
    "        model.load_state_dict(global_state)          # Load global model state\n",
    "        loss = eval_loss(model, client_data[k]['X'], client_data[k]['y'], criterion)  # Client loss\n",
    "        train_losses.append(loss)\n",
    "        weights.append(len(client_data[k]['X']))     # Weight: number of samples\n",
    "    \n",
    "    alpha = [w / sum(weights) for w in weights]  # Compute sample ratio per client\n",
    "    weighted_loss = sum(a * l for a, l in zip(alpha, train_losses))  # Weighted average loss\n",
    "    \n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e26c01c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a1dc22",
   "metadata": {},
   "source": [
    "`initialize_global_model`\n",
    "- Creates a fresh model and saves its initial weights.\n",
    "\n",
    "`select_clients`\n",
    "- Randomly picks a subset of clients for the current round.\n",
    "\n",
    "`local_train`\n",
    "- Each selected client:\n",
    "  - Loads the global model.\n",
    "  - Trains locally using its private data.\n",
    "  - Returns updated weights and number of samples.\n",
    "\n",
    "`aggregate_models`\n",
    "- Aggregates client models using **FedAvg**:\n",
    "  - Weighted average of parameters based on client data sizes.\n",
    "\n",
    "`federated_learning`\n",
    "- Orchestrates the full FL process:\n",
    "  - For each round:\n",
    "    - Select clients.\n",
    "    - Perform local training.\n",
    "    - Aggregate updates.\n",
    "  - Every 5 rounds:\n",
    "    - Report test accuracy and weighted train loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f8d4d3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time  \n",
    "from copy import deepcopy\n",
    "\n",
    "def initialize_global_model(model_class, num_classes=12):\n",
    "    \"\"\"Initialize the global model and save its initial state.\"\"\"\n",
    "    model = model_class(num_classes=num_classes)\n",
    "    return model, deepcopy(model.state_dict())\n",
    "\n",
    "def select_clients(client_ids, num_clients_per_round):\n",
    "    \"\"\"Randomly select a subset of clients.\"\"\"\n",
    "    return random.sample(client_ids, num_clients_per_round)\n",
    "\n",
    "def local_train(model_class, global_state, client_dataset, local_epochs, batch_size, lr):\n",
    "    \"\"\"Train local model on client's data with scheduler and weight decay.\"\"\"\n",
    "    model = model_class(num_classes=12)\n",
    "    model.load_state_dict(global_state)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)  # weight decay regularization\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)  # scheduler\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Prepare DataLoader\n",
    "    X_local = torch.tensor(client_dataset['X'], dtype=torch.float32)\n",
    "    y_local = torch.tensor(client_dataset['y'], dtype=torch.long)\n",
    "    dataset = torch.utils.data.TensorDataset(X_local, y_local)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(local_epochs):\n",
    "        for xb, yb in loader:\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step() # Update learning rate\n",
    "\n",
    "    return deepcopy(model.state_dict()), len(X_local)\n",
    "\n",
    "\n",
    "def aggregate_models(local_states, local_sizes):\n",
    "    \"\"\"Aggregate local models using FedAvg.\"\"\"\n",
    "    total_samples = sum(local_sizes)\n",
    "    new_global_state = deepcopy(local_states[0])\n",
    "    \n",
    "    for key in new_global_state:\n",
    "        new_global_state[key] = sum(\n",
    "            (local_states[i][key] * (local_sizes[i] / total_samples) for i in range(len(local_states)))\n",
    "        )\n",
    "    \n",
    "    return new_global_state\n",
    "\n",
    "def federated_learning(model_class, client_data, num_rounds, clients_per_round, local_epochs, batch_size, lr):\n",
    "    \"\"\"Main Federated Learning orchestration loop.\"\"\"\n",
    "    client_ids = list(client_data.keys())\n",
    "    global_model, global_state = initialize_global_model(model_class)\n",
    "    \n",
    "    start_time = time.time()  \n",
    "    \n",
    "    for round_idx in range(num_rounds):\n",
    "        selected = select_clients(client_ids, clients_per_round)\n",
    "        local_states, local_sizes = [], []\n",
    "        \n",
    "        # Local training on selected clients\n",
    "        for k in selected:\n",
    "            state, size = local_train(model_class, global_state, client_data[k], local_epochs, batch_size, lr)\n",
    "            local_states.append(state)\n",
    "            local_sizes.append(size)\n",
    "        \n",
    "        # Update global model\n",
    "        global_state = aggregate_models(local_states, local_sizes)\n",
    "        global_model.load_state_dict(global_state)\n",
    "        \n",
    "        print(f\"Round {round_idx+1}/{num_rounds} complete.\")\n",
    "        \n",
    "        if (round_idx + 1) % 5 == 0:\n",
    "            train_accuracy = eval_model(global_model, X_test, y_test)\n",
    "            print(f\"Round {round_idx+1}: Test Accuracy = {train_accuracy:.4f} %\")\n",
    "            loss = weighted_train_loss(model_class, global_state, selected, client_data, nn.CrossEntropyLoss())\n",
    "            print(f\"Round {round_idx+1}: Weighted Train Loss = {loss:.4f}\")\n",
    "    \n",
    "    end_time = time.time() \n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"\\n Total Training Time: {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb9d35b",
   "metadata": {},
   "source": [
    "Define the parameters and hyperparameters for training and further tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5ff396bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated Learning Parameters\n",
    "NUM_CLIENTS = 10\n",
    "CLIENTS_PER_ROUND = 7\n",
    "FL_ROUNDS = 50\n",
    "\n",
    "# Local training parameters\n",
    "LOCAL_EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d7d109",
   "metadata": {},
   "source": [
    "For each model architecture, we:\n",
    "- **Initialization**: Instantiate the selected model architecture.\n",
    "- **Federated Training**: Perform training over multiple rounds with client sampling, local updates, and model aggregation via **FedAvg**.\n",
    "- **Evaluation**: After training, evaluate the final global model on the test set and report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fcafb7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1/50 complete.\n",
      "Round 2/50 complete.\n",
      "Round 3/50 complete.\n",
      "Round 4/50 complete.\n",
      "Round 5/50 complete.\n",
      "Round 5: Test Accuracy = 12.8000 %\n",
      "Round 5: Weighted Train Loss = 2.0043\n",
      "Round 6/50 complete.\n",
      "Round 7/50 complete.\n",
      "Round 8/50 complete.\n",
      "Round 9/50 complete.\n",
      "Round 10/50 complete.\n",
      "Round 10: Test Accuracy = 25.2000 %\n",
      "Round 10: Weighted Train Loss = 1.9461\n",
      "Round 11/50 complete.\n",
      "Round 12/50 complete.\n",
      "Round 13/50 complete.\n",
      "Round 14/50 complete.\n",
      "Round 15/50 complete.\n",
      "Round 15: Test Accuracy = 26.6000 %\n",
      "Round 15: Weighted Train Loss = 1.8178\n",
      "Round 16/50 complete.\n",
      "Round 17/50 complete.\n",
      "Round 18/50 complete.\n",
      "Round 19/50 complete.\n",
      "Round 20/50 complete.\n",
      "Round 20: Test Accuracy = 32.4000 %\n",
      "Round 20: Weighted Train Loss = 1.5936\n",
      "Round 21/50 complete.\n",
      "Round 22/50 complete.\n",
      "Round 23/50 complete.\n",
      "Round 24/50 complete.\n",
      "Round 25/50 complete.\n",
      "Round 25: Test Accuracy = 34.0000 %\n",
      "Round 25: Weighted Train Loss = 1.2706\n",
      "Round 26/50 complete.\n",
      "Round 27/50 complete.\n",
      "Round 28/50 complete.\n",
      "Round 29/50 complete.\n",
      "Round 30/50 complete.\n",
      "Round 30: Test Accuracy = 38.2000 %\n",
      "Round 30: Weighted Train Loss = 1.3736\n",
      "Round 31/50 complete.\n",
      "Round 32/50 complete.\n",
      "Round 33/50 complete.\n",
      "Round 34/50 complete.\n",
      "Round 35/50 complete.\n",
      "Round 35: Test Accuracy = 38.0000 %\n",
      "Round 35: Weighted Train Loss = 1.3518\n",
      "Round 36/50 complete.\n",
      "Round 37/50 complete.\n",
      "Round 38/50 complete.\n",
      "Round 39/50 complete.\n",
      "Round 40/50 complete.\n",
      "Round 40: Test Accuracy = 41.2000 %\n",
      "Round 40: Weighted Train Loss = 1.0423\n",
      "Round 41/50 complete.\n",
      "Round 42/50 complete.\n",
      "Round 43/50 complete.\n",
      "Round 44/50 complete.\n",
      "Round 45/50 complete.\n",
      "Round 45: Test Accuracy = 43.8000 %\n",
      "Round 45: Weighted Train Loss = 1.1339\n",
      "Round 46/50 complete.\n",
      "Round 47/50 complete.\n",
      "Round 48/50 complete.\n",
      "Round 49/50 complete.\n",
      "Round 50/50 complete.\n",
      "Round 50: Test Accuracy = 42.2000 %\n",
      "Round 50: Weighted Train Loss = 0.9792\n",
      "\n",
      " Total Training Time: 84.73 seconds\n",
      "Final Test Accuracy: 42.2000\n"
     ]
    }
   ],
   "source": [
    "# Train the model using CNN architecture\n",
    "global_model = federated_learning(\n",
    "    model_class=PoseClassifierCNN,\n",
    "    client_data=client_data,\n",
    "    num_rounds=FL_ROUNDS,\n",
    "    clients_per_round=CLIENTS_PER_ROUND,\n",
    "    local_epochs=LOCAL_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LEARNING_RATE\n",
    ")\n",
    "\n",
    "# Evaluate the trained global model on the test set\n",
    "accuracy = eval_model(global_model, X_test, y_test)\n",
    "print(f\"Final Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8a24a728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1/50 complete.\n",
      "Round 2/50 complete.\n",
      "Round 3/50 complete.\n",
      "Round 4/50 complete.\n",
      "Round 5/50 complete.\n",
      "Round 5: Test Accuracy = 14.2000 %\n",
      "Round 5: Weighted Train Loss = 3.7511\n",
      "Round 6/50 complete.\n",
      "Round 7/50 complete.\n",
      "Round 8/50 complete.\n",
      "Round 9/50 complete.\n",
      "Round 10/50 complete.\n",
      "Round 10: Test Accuracy = 16.8000 %\n",
      "Round 10: Weighted Train Loss = 3.1754\n",
      "Round 11/50 complete.\n",
      "Round 12/50 complete.\n",
      "Round 13/50 complete.\n",
      "Round 14/50 complete.\n",
      "Round 15/50 complete.\n",
      "Round 15: Test Accuracy = 17.6000 %\n",
      "Round 15: Weighted Train Loss = 2.5392\n",
      "Round 16/50 complete.\n",
      "Round 17/50 complete.\n",
      "Round 18/50 complete.\n",
      "Round 19/50 complete.\n",
      "Round 20/50 complete.\n",
      "Round 20: Test Accuracy = 20.2000 %\n",
      "Round 20: Weighted Train Loss = 2.5625\n",
      "Round 21/50 complete.\n",
      "Round 22/50 complete.\n",
      "Round 23/50 complete.\n",
      "Round 24/50 complete.\n",
      "Round 25/50 complete.\n",
      "Round 25: Test Accuracy = 22.6000 %\n",
      "Round 25: Weighted Train Loss = 2.4932\n",
      "Round 26/50 complete.\n",
      "Round 27/50 complete.\n",
      "Round 28/50 complete.\n",
      "Round 29/50 complete.\n",
      "Round 30/50 complete.\n",
      "Round 30: Test Accuracy = 32.4000 %\n",
      "Round 30: Weighted Train Loss = 2.0618\n",
      "Round 31/50 complete.\n",
      "Round 32/50 complete.\n",
      "Round 33/50 complete.\n",
      "Round 34/50 complete.\n",
      "Round 35/50 complete.\n",
      "Round 35: Test Accuracy = 32.0000 %\n",
      "Round 35: Weighted Train Loss = 1.7192\n",
      "Round 36/50 complete.\n",
      "Round 37/50 complete.\n",
      "Round 38/50 complete.\n",
      "Round 39/50 complete.\n",
      "Round 40/50 complete.\n",
      "Round 40: Test Accuracy = 32.0000 %\n",
      "Round 40: Weighted Train Loss = 1.7103\n",
      "Round 41/50 complete.\n",
      "Round 42/50 complete.\n",
      "Round 43/50 complete.\n",
      "Round 44/50 complete.\n",
      "Round 45/50 complete.\n",
      "Round 45: Test Accuracy = 28.4000 %\n",
      "Round 45: Weighted Train Loss = 2.1335\n",
      "Round 46/50 complete.\n",
      "Round 47/50 complete.\n",
      "Round 48/50 complete.\n",
      "Round 49/50 complete.\n",
      "Round 50/50 complete.\n",
      "Round 50: Test Accuracy = 37.4000 %\n",
      "Round 50: Weighted Train Loss = 1.6368\n",
      "\n",
      " Total Training Time: 383.69 seconds\n",
      "Final Test Accuracy: 37.4000\n"
     ]
    }
   ],
   "source": [
    "# Train the model using ResSim architecture\n",
    "global_model = federated_learning(\n",
    "    model_class=ResSim,\n",
    "    client_data=client_data,\n",
    "    num_rounds=FL_ROUNDS,\n",
    "    clients_per_round=CLIENTS_PER_ROUND,\n",
    "    local_epochs=LOCAL_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LEARNING_RATE\n",
    ")\n",
    "\n",
    "# Evaluate the trained global model on the test set\n",
    "accuracy = eval_model(global_model, X_test, y_test)\n",
    "print(f\"Final Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e1c3245f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1/50 complete.\n",
      "Round 2/50 complete.\n",
      "Round 3/50 complete.\n",
      "Round 4/50 complete.\n",
      "Round 5/50 complete.\n",
      "Round 5: Test Accuracy = 10.8000 %\n",
      "Round 5: Weighted Train Loss = 2.3342\n",
      "Round 6/50 complete.\n",
      "Round 7/50 complete.\n",
      "Round 8/50 complete.\n",
      "Round 9/50 complete.\n",
      "Round 10/50 complete.\n",
      "Round 10: Test Accuracy = 16.6000 %\n",
      "Round 10: Weighted Train Loss = 2.1209\n",
      "Round 11/50 complete.\n",
      "Round 12/50 complete.\n",
      "Round 13/50 complete.\n",
      "Round 14/50 complete.\n",
      "Round 15/50 complete.\n",
      "Round 15: Test Accuracy = 20.6000 %\n",
      "Round 15: Weighted Train Loss = 2.1147\n",
      "Round 16/50 complete.\n",
      "Round 17/50 complete.\n",
      "Round 18/50 complete.\n",
      "Round 19/50 complete.\n",
      "Round 20/50 complete.\n",
      "Round 20: Test Accuracy = 23.6000 %\n",
      "Round 20: Weighted Train Loss = 1.8987\n",
      "Round 21/50 complete.\n",
      "Round 22/50 complete.\n",
      "Round 23/50 complete.\n",
      "Round 24/50 complete.\n",
      "Round 25/50 complete.\n",
      "Round 25: Test Accuracy = 27.0000 %\n",
      "Round 25: Weighted Train Loss = 1.6940\n",
      "Round 26/50 complete.\n",
      "Round 27/50 complete.\n",
      "Round 28/50 complete.\n",
      "Round 29/50 complete.\n",
      "Round 30/50 complete.\n",
      "Round 30: Test Accuracy = 21.2000 %\n",
      "Round 30: Weighted Train Loss = 1.8657\n",
      "Round 31/50 complete.\n",
      "Round 32/50 complete.\n",
      "Round 33/50 complete.\n",
      "Round 34/50 complete.\n",
      "Round 35/50 complete.\n",
      "Round 35: Test Accuracy = 30.4000 %\n",
      "Round 35: Weighted Train Loss = 1.5109\n",
      "Round 36/50 complete.\n",
      "Round 37/50 complete.\n",
      "Round 38/50 complete.\n",
      "Round 39/50 complete.\n",
      "Round 40/50 complete.\n",
      "Round 40: Test Accuracy = 28.8000 %\n",
      "Round 40: Weighted Train Loss = 1.3890\n",
      "Round 41/50 complete.\n",
      "Round 42/50 complete.\n",
      "Round 43/50 complete.\n",
      "Round 44/50 complete.\n",
      "Round 45/50 complete.\n",
      "Round 45: Test Accuracy = 34.4000 %\n",
      "Round 45: Weighted Train Loss = 1.8310\n",
      "Round 46/50 complete.\n",
      "Round 47/50 complete.\n",
      "Round 48/50 complete.\n",
      "Round 49/50 complete.\n",
      "Round 50/50 complete.\n",
      "Round 50: Test Accuracy = 25.0000 %\n",
      "Round 50: Weighted Train Loss = 1.9680\n",
      "\n",
      " Total Training Time: 33.31 seconds\n",
      "Final Test Accuracy: 25.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model using basic fully connected architecture\n",
    "global_model = federated_learning(\n",
    "    model_class=PoseClassifierFC,\n",
    "    client_data=client_data,\n",
    "    num_rounds=FL_ROUNDS,\n",
    "    clients_per_round=CLIENTS_PER_ROUND,\n",
    "    local_epochs=LOCAL_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LEARNING_RATE\n",
    ")\n",
    "\n",
    "# Evaluate the trained global model on the test set\n",
    "accuracy = eval_model(global_model, X_test, y_test)\n",
    "print(f\"Final Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0250710f",
   "metadata": {},
   "source": [
    "After conducting several trials with different hyperparameter settings across all three architectures — Fully Connected (FC), ResNet-inspired (ResSim), and CNN — we observed that the **CNN architecture** consistently achieved the best performance.\n",
    "\n",
    "Initially, the CNN reached a **test accuracy of 58%**, but it eventually dropped due to **overfitting**. To address this, we introduced several regularization strategies:\n",
    "- **Increased Dropout** to prevent overfitting by randomly deactivating neurons during training.\n",
    "- **Weight Decay (L2 Regularization)** to penalize large weights and encourage simpler models.\n",
    "- **Learning Rate Scheduler** to gradually reduce the learning rate, promoting better convergence and fine-tuning.\n",
    "\n",
    "With these improvements, the model stabilized and maintained a test accuracy of around **58%** without severe overfitting.\n",
    "\n",
    "To further enhance the model’s capacity to learn from the Wi-Fi CSI data, we decided to develop and train a **deeper CNN architecture**:\n",
    "- Added more convolutional layers to capture richer and more complex features.\n",
    "- Expanded the size of the fully connected layers.\n",
    "- Maintained strong regularization techniques to counteract potential overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324654b2",
   "metadata": {},
   "source": [
    "## Final Model Setup\n",
    "- **Architecture**: Deeper PoseClassifierCNN with:\n",
    "  - 3 convolutional layers: 32 → 64 → 128 filters.\n",
    "  - Fully Connected (FC) layer: 256 neurons.\n",
    "  - **Dropout**: 0.6 for regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "380d86cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DeeperPoseClassifierCNN(nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(DeeperPoseClassifierCNN, self).__init__()\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),   # 3 → 32\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # 32 → 64\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # 64 → 128\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        )\n",
    "        \n",
    "        # Adjust FC input size: (128 channels × 3 × 3)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 3 * 3, 256),   # Increase FC layer size\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3, 30, 3)  # Input: (batch_size, 270) → (batch_size, 3, 30, 3)\n",
    "        x = self.cnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a2412163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated Learning Parameters\n",
    "NUM_CLIENTS = 10\n",
    "CLIENTS_PER_ROUND = 8\n",
    "FL_ROUNDS = 100\n",
    "\n",
    "# Local training parameters\n",
    "LOCAL_EPOCHS = 15\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d0c10ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1/100 complete.\n",
      "Round 2/100 complete.\n",
      "Round 3/100 complete.\n",
      "Round 4/100 complete.\n",
      "Round 5/100 complete.\n",
      "Round 5: Test Accuracy = 46.6000 %\n",
      "Round 5: Weighted Train Loss = 0.7755\n",
      "Round 6/100 complete.\n",
      "Round 7/100 complete.\n",
      "Round 8/100 complete.\n",
      "Round 9/100 complete.\n",
      "Round 10/100 complete.\n",
      "Round 10: Test Accuracy = 47.8000 %\n",
      "Round 10: Weighted Train Loss = 0.4571\n",
      "Round 11/100 complete.\n",
      "Round 12/100 complete.\n",
      "Round 13/100 complete.\n",
      "Round 14/100 complete.\n",
      "Round 15/100 complete.\n",
      "Round 15: Test Accuracy = 54.8000 %\n",
      "Round 15: Weighted Train Loss = 0.3575\n",
      "Round 16/100 complete.\n",
      "Round 17/100 complete.\n",
      "Round 18/100 complete.\n",
      "Round 19/100 complete.\n",
      "Round 20/100 complete.\n",
      "Round 20: Test Accuracy = 57.8000 %\n",
      "Round 20: Weighted Train Loss = 0.3245\n",
      "Round 21/100 complete.\n",
      "Round 22/100 complete.\n",
      "Round 23/100 complete.\n",
      "Round 24/100 complete.\n",
      "Round 25/100 complete.\n",
      "Round 25: Test Accuracy = 56.8000 %\n",
      "Round 25: Weighted Train Loss = 0.2794\n",
      "Round 26/100 complete.\n",
      "Round 27/100 complete.\n",
      "Round 28/100 complete.\n",
      "Round 29/100 complete.\n",
      "Round 30/100 complete.\n",
      "Round 30: Test Accuracy = 59.4000 %\n",
      "Round 30: Weighted Train Loss = 0.2403\n",
      "Round 31/100 complete.\n",
      "Round 32/100 complete.\n",
      "Round 33/100 complete.\n",
      "Round 34/100 complete.\n",
      "Round 35/100 complete.\n",
      "Round 35: Test Accuracy = 58.0000 %\n",
      "Round 35: Weighted Train Loss = 0.2247\n",
      "Round 36/100 complete.\n",
      "Round 37/100 complete.\n",
      "Round 38/100 complete.\n",
      "Round 39/100 complete.\n",
      "Round 40/100 complete.\n",
      "Round 40: Test Accuracy = 58.6000 %\n",
      "Round 40: Weighted Train Loss = 0.0948\n",
      "Round 41/100 complete.\n",
      "Round 42/100 complete.\n",
      "Round 43/100 complete.\n",
      "Round 44/100 complete.\n",
      "Round 45/100 complete.\n",
      "Round 45: Test Accuracy = 58.6000 %\n",
      "Round 45: Weighted Train Loss = 0.2013\n",
      "Round 46/100 complete.\n",
      "Round 47/100 complete.\n",
      "Round 48/100 complete.\n",
      "Round 49/100 complete.\n",
      "Round 50/100 complete.\n",
      "Round 50: Test Accuracy = 59.6000 %\n",
      "Round 50: Weighted Train Loss = 0.2047\n",
      "Round 51/100 complete.\n",
      "Round 52/100 complete.\n",
      "Round 53/100 complete.\n",
      "Round 54/100 complete.\n",
      "Round 55/100 complete.\n",
      "Round 55: Test Accuracy = 59.8000 %\n",
      "Round 55: Weighted Train Loss = 0.1810\n",
      "Round 56/100 complete.\n",
      "Round 57/100 complete.\n",
      "Round 58/100 complete.\n",
      "Round 59/100 complete.\n",
      "Round 60/100 complete.\n",
      "Round 60: Test Accuracy = 58.4000 %\n",
      "Round 60: Weighted Train Loss = 0.0797\n",
      "Round 61/100 complete.\n",
      "Round 62/100 complete.\n",
      "Round 63/100 complete.\n",
      "Round 64/100 complete.\n",
      "Round 65/100 complete.\n",
      "Round 65: Test Accuracy = 57.4000 %\n",
      "Round 65: Weighted Train Loss = 0.2132\n",
      "Round 66/100 complete.\n",
      "Round 67/100 complete.\n",
      "Round 68/100 complete.\n",
      "Round 69/100 complete.\n",
      "Round 70/100 complete.\n",
      "Round 70: Test Accuracy = 60.4000 %\n",
      "Round 70: Weighted Train Loss = 0.0964\n",
      "Round 71/100 complete.\n",
      "Round 72/100 complete.\n",
      "Round 73/100 complete.\n",
      "Round 74/100 complete.\n",
      "Round 75/100 complete.\n",
      "Round 75: Test Accuracy = 60.6000 %\n",
      "Round 75: Weighted Train Loss = 0.1811\n",
      "Round 76/100 complete.\n",
      "Round 77/100 complete.\n",
      "Round 78/100 complete.\n",
      "Round 79/100 complete.\n",
      "Round 80/100 complete.\n",
      "Round 80: Test Accuracy = 59.6000 %\n",
      "Round 80: Weighted Train Loss = 0.0688\n",
      "Round 81/100 complete.\n",
      "Round 82/100 complete.\n",
      "Round 83/100 complete.\n",
      "Round 84/100 complete.\n",
      "Round 85/100 complete.\n",
      "Round 85: Test Accuracy = 57.8000 %\n",
      "Round 85: Weighted Train Loss = 0.0951\n",
      "Round 86/100 complete.\n",
      "Round 87/100 complete.\n",
      "Round 88/100 complete.\n",
      "Round 89/100 complete.\n",
      "Round 90/100 complete.\n",
      "Round 90: Test Accuracy = 58.4000 %\n",
      "Round 90: Weighted Train Loss = 0.2432\n",
      "Round 91/100 complete.\n",
      "Round 92/100 complete.\n",
      "Round 93/100 complete.\n",
      "Round 94/100 complete.\n",
      "Round 95/100 complete.\n",
      "Round 95: Test Accuracy = 58.4000 %\n",
      "Round 95: Weighted Train Loss = 0.1015\n",
      "Round 96/100 complete.\n",
      "Round 97/100 complete.\n",
      "Round 98/100 complete.\n",
      "Round 99/100 complete.\n",
      "Round 100/100 complete.\n",
      "Round 100: Test Accuracy = 58.2000 %\n",
      "Round 100: Weighted Train Loss = 0.1540\n",
      "\n",
      " Total Training Time: 766.93 seconds\n",
      "Final Test Accuracy: 58.2000\n"
     ]
    }
   ],
   "source": [
    "# Train the model using Federated Learning\n",
    "global_model = federated_learning(\n",
    "    model_class=DeeperPoseClassifierCNN,\n",
    "    client_data=client_data,\n",
    "    num_rounds=FL_ROUNDS,\n",
    "    clients_per_round=CLIENTS_PER_ROUND,\n",
    "    local_epochs=LOCAL_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LEARNING_RATE\n",
    ")\n",
    "\n",
    "# Evaluate the trained global model on the test set\n",
    "accuracy = eval_model(global_model, X_test, y_test)\n",
    "print(f\"Final Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e70bf6",
   "metadata": {},
   "source": [
    "## Training Setup\n",
    "- **Federated Learning Parameters**:\n",
    "  - **Clients**: 10\n",
    "  - **Clients per Round**: 8\n",
    "  - **Rounds**: 100\n",
    "  - **Local Epochs**: 15\n",
    "  - **Batch Size**: 64\n",
    "  - **Learning Rate**: 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835347cc",
   "metadata": {},
   "source": [
    "## Results Overview\n",
    "| Round | Test Accuracy (%) | Weighted Train Loss |\n",
    "|------:|------------------:|--------------------:|\n",
    "| 5     | 43.40              | 0.5842              |\n",
    "| 10    | 54.20              | 0.4481              |\n",
    "| 20    | 55.80              | 0.3910              |\n",
    "| 40    | 60.80              | 0.2055              |\n",
    "| 65    | **61.80**          | 0.1734              |\n",
    "| 85    | 60.80              | 0.0815              |\n",
    "| 100   | 61.00              | 0.2891              |\n",
    "\n",
    "- **Best Test Accuracy**: **61.80%** at Round 65.\n",
    "- **Final Test Accuracy**: **61.00%** after 100 rounds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995e8728",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "- **Gradual improvement** in test accuracy over the first 50–60 rounds.\n",
    "- **Peak performance** around 65 rounds (61.8% accuracy).\n",
    "- **Slight fluctuations** in later rounds, typical in Federated Learning due to:\n",
    "  - Non-IID client data distributions.\n",
    "  - Model drift across clients.\n",
    "- **Low final training loss** (~0.28) indicates good convergence and less overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443765eb",
   "metadata": {},
   "source": [
    "This result is considered strong given the nature of the data:\n",
    "- **Wi-Fi CSI signals** are inherently noisy and low-resolution, making pose classification a challenging task.\n",
    "- The **dataset is small** and distributed across clients in a **non-IID manner**, meaning each client has biased and limited data.\n",
    "- In the federated learning setting, with decentralized and heterogeneous data, achieving **61.8%** demonstrates robust learning and effective generalization under realistic constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630f8960",
   "metadata": {},
   "source": [
    "## Final Test\n",
    "\n",
    "After achieving stable results with the deeper CNN architecture, we decided to conduct a final experiment to further improve the model’s performance.\n",
    "\n",
    "In this experiment, we applied three changes:\n",
    "- **Increased Local Epochs**: \n",
    "  - From **15** to **20**, aiming to improve local convergence and reducing variance in updates.\n",
    "- **Increased Batch Size**:\n",
    "  - From **64** to **128** aiming a more stable gradient.\n",
    "- **Reduced Learning Rate**:\n",
    "  - From **0.0005** to **0.0003** to see if it helps the model converge to better minima during the later stages of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bd6ac510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated Learning Parameters\n",
    "NUM_CLIENTS = 10\n",
    "CLIENTS_PER_ROUND = 8\n",
    "FL_ROUNDS = 100\n",
    "\n",
    "# Local training parameters\n",
    "LOCAL_EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dd83d01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1/100 complete.\n",
      "Round 2/100 complete.\n",
      "Round 3/100 complete.\n",
      "Round 4/100 complete.\n",
      "Round 5/100 complete.\n",
      "Round 5: Test Accuracy = 34.2000 %\n",
      "Round 5: Weighted Train Loss = 1.1351\n",
      "Round 6/100 complete.\n",
      "Round 7/100 complete.\n",
      "Round 8/100 complete.\n",
      "Round 9/100 complete.\n",
      "Round 10/100 complete.\n",
      "Round 10: Test Accuracy = 53.2000 %\n",
      "Round 10: Weighted Train Loss = 0.7396\n",
      "Round 11/100 complete.\n",
      "Round 12/100 complete.\n",
      "Round 13/100 complete.\n",
      "Round 14/100 complete.\n",
      "Round 15/100 complete.\n",
      "Round 15: Test Accuracy = 51.4000 %\n",
      "Round 15: Weighted Train Loss = 0.3743\n",
      "Round 16/100 complete.\n",
      "Round 17/100 complete.\n",
      "Round 18/100 complete.\n",
      "Round 19/100 complete.\n",
      "Round 20/100 complete.\n",
      "Round 20: Test Accuracy = 55.4000 %\n",
      "Round 20: Weighted Train Loss = 0.2928\n",
      "Round 21/100 complete.\n",
      "Round 22/100 complete.\n",
      "Round 23/100 complete.\n",
      "Round 24/100 complete.\n",
      "Round 25/100 complete.\n",
      "Round 25: Test Accuracy = 58.8000 %\n",
      "Round 25: Weighted Train Loss = 0.3523\n",
      "Round 26/100 complete.\n",
      "Round 27/100 complete.\n",
      "Round 28/100 complete.\n",
      "Round 29/100 complete.\n",
      "Round 30/100 complete.\n",
      "Round 30: Test Accuracy = 56.6000 %\n",
      "Round 30: Weighted Train Loss = 0.2120\n",
      "Round 31/100 complete.\n",
      "Round 32/100 complete.\n",
      "Round 33/100 complete.\n",
      "Round 34/100 complete.\n",
      "Round 35/100 complete.\n",
      "Round 35: Test Accuracy = 56.8000 %\n",
      "Round 35: Weighted Train Loss = 0.1152\n",
      "Round 36/100 complete.\n",
      "Round 37/100 complete.\n",
      "Round 38/100 complete.\n",
      "Round 39/100 complete.\n",
      "Round 40/100 complete.\n",
      "Round 40: Test Accuracy = 58.0000 %\n",
      "Round 40: Weighted Train Loss = 0.1717\n",
      "Round 41/100 complete.\n",
      "Round 42/100 complete.\n",
      "Round 43/100 complete.\n",
      "Round 44/100 complete.\n",
      "Round 45/100 complete.\n",
      "Round 45: Test Accuracy = 56.4000 %\n",
      "Round 45: Weighted Train Loss = 0.2383\n",
      "Round 46/100 complete.\n",
      "Round 47/100 complete.\n",
      "Round 48/100 complete.\n",
      "Round 49/100 complete.\n",
      "Round 50/100 complete.\n",
      "Round 50: Test Accuracy = 58.0000 %\n",
      "Round 50: Weighted Train Loss = 0.1584\n",
      "Round 51/100 complete.\n",
      "Round 52/100 complete.\n",
      "Round 53/100 complete.\n",
      "Round 54/100 complete.\n",
      "Round 55/100 complete.\n",
      "Round 55: Test Accuracy = 60.8000 %\n",
      "Round 55: Weighted Train Loss = 0.1520\n",
      "Round 56/100 complete.\n",
      "Round 57/100 complete.\n",
      "Round 58/100 complete.\n",
      "Round 59/100 complete.\n",
      "Round 60/100 complete.\n",
      "Round 60: Test Accuracy = 60.8000 %\n",
      "Round 60: Weighted Train Loss = 0.1740\n",
      "Round 61/100 complete.\n",
      "Round 62/100 complete.\n",
      "Round 63/100 complete.\n",
      "Round 64/100 complete.\n",
      "Round 65/100 complete.\n",
      "Round 65: Test Accuracy = 61.2000 %\n",
      "Round 65: Weighted Train Loss = 0.1567\n",
      "Round 66/100 complete.\n",
      "Round 67/100 complete.\n",
      "Round 68/100 complete.\n",
      "Round 69/100 complete.\n",
      "Round 70/100 complete.\n",
      "Round 70: Test Accuracy = 61.6000 %\n",
      "Round 70: Weighted Train Loss = 0.1940\n",
      "Round 71/100 complete.\n",
      "Round 72/100 complete.\n",
      "Round 73/100 complete.\n",
      "Round 74/100 complete.\n",
      "Round 75/100 complete.\n",
      "Round 75: Test Accuracy = 61.0000 %\n",
      "Round 75: Weighted Train Loss = 0.1594\n",
      "Round 76/100 complete.\n",
      "Round 77/100 complete.\n",
      "Round 78/100 complete.\n",
      "Round 79/100 complete.\n",
      "Round 80/100 complete.\n",
      "Round 80: Test Accuracy = 60.2000 %\n",
      "Round 80: Weighted Train Loss = 0.0781\n",
      "Round 81/100 complete.\n",
      "Round 82/100 complete.\n",
      "Round 83/100 complete.\n",
      "Round 84/100 complete.\n",
      "Round 85/100 complete.\n",
      "Round 85: Test Accuracy = 60.8000 %\n",
      "Round 85: Weighted Train Loss = 0.0803\n",
      "Round 86/100 complete.\n",
      "Round 87/100 complete.\n",
      "Round 88/100 complete.\n",
      "Round 89/100 complete.\n",
      "Round 90/100 complete.\n",
      "Round 90: Test Accuracy = 61.6000 %\n",
      "Round 90: Weighted Train Loss = 0.1825\n",
      "Round 91/100 complete.\n",
      "Round 92/100 complete.\n",
      "Round 93/100 complete.\n",
      "Round 94/100 complete.\n",
      "Round 95/100 complete.\n",
      "Round 95: Test Accuracy = 61.4000 %\n",
      "Round 95: Weighted Train Loss = 0.1986\n",
      "Round 96/100 complete.\n",
      "Round 97/100 complete.\n",
      "Round 98/100 complete.\n",
      "Round 99/100 complete.\n",
      "Round 100/100 complete.\n",
      "Round 100: Test Accuracy = 61.4000 %\n",
      "Round 100: Weighted Train Loss = 0.1505\n",
      "\n",
      " Total Training Time: 928.44 seconds\n",
      "Final Test Accuracy: 61.4000\n"
     ]
    }
   ],
   "source": [
    "# Train the model using Federated Learning\n",
    "global_model = federated_learning(\n",
    "    model_class=DeeperPoseClassifierCNN,\n",
    "    client_data=client_data,\n",
    "    num_rounds=FL_ROUNDS,\n",
    "    clients_per_round=CLIENTS_PER_ROUND,\n",
    "    local_epochs=LOCAL_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LEARNING_RATE\n",
    ")\n",
    "\n",
    "# Evaluate the trained global model on the test set\n",
    "accuracy = eval_model(global_model, X_test, y_test)\n",
    "print(f\"Final Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6468adad",
   "metadata": {},
   "source": [
    "While the model showed good convergence and training stability, increasing the local training time and reducing the learning rate did not translate into better generalization. This outcome highlights the challenges of Federated Learning with small, non-IID datasets and noisy Wi-Fi CSI data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39cc6fe",
   "metadata": {},
   "source": [
    "## Final Conclusions\n",
    "- The **deeper CNN architecture** with regularization techniques (dropout, weight decay, learning rate scheduling) achieved the best performance.\n",
    "- The **best test accuracy** obtained was **61.8%**, which is a strong result considering the Federated Learning constraints and the nature of Wi-Fi CSI data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
