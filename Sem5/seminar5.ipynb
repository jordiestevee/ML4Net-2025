{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d87ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79c4139",
   "metadata": {},
   "source": [
    " # Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c453e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 270)\n",
      "(64,)\n",
      "(500, 270)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'dataset_Seminar5'\n",
    "num_clients = 10\n",
    "client_data = {}\n",
    "\n",
    "# Load each client’s training data\n",
    "for i in range(1, num_clients + 1):\n",
    "    X_path = os.path.join(data_dir, f'client_datasets/client_{i}_features.csv')\n",
    "    y_path = os.path.join(data_dir, f'client_datasets/client_{i}_labels.csv')\n",
    "    \n",
    "    X = pd.read_csv(X_path, header=None).values  # shape: (num_samples, 270)\n",
    "    y = pd.read_csv(y_path, header=None).values.flatten()  # shape: (num_samples,)\n",
    "    \n",
    "    client_data[i] = {'X': X, 'y': y}\n",
    "\n",
    "# Load test data\n",
    "X_test = pd.read_csv(os.path.join(data_dir, 'test_features.csv'), header=None).values\n",
    "y_test = pd.read_csv(os.path.join(data_dir, 'test_labels.csv'), header=None).values.flatten()\n",
    "\n",
    "print(X.shape)  # shape: (num_samples, 270)\n",
    "print(y.shape)  # shape: (num_samples,)\n",
    "print(X_test.shape)  # shape: (num_samples, 270)\n",
    "print(y_test.shape)  # shape: (num_samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b388d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for client_id in client_data:\n",
    "    client_data[client_id]['y'] -= 1  # Now ranges 0-11\n",
    "\n",
    "y_test -= 1  # Also adjust test labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b0c94",
   "metadata": {},
   "source": [
    "Chosen architecture: CNN (Ressim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efedb4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResSim(nn.Module):\n",
    "    \"\"\"\n",
    "    A simplified ResNet-style network with residual connections and sequential blocks.\n",
    "    \n",
    "    Adapted for CSI input (flattened to 3x30x3).\n",
    "\n",
    "    Architecture:\n",
    "        - Two residual blocks: Conv → ReLU → Conv + skip\n",
    "        - Each followed by MaxPool\n",
    "        - Fully connected classifier\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): Number of output classes.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=12): # 12 different pose classes\n",
    "        super(ResSim, self).__init__()\n",
    "\n",
    "        # Block 1\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.shortcut1 = nn.Conv2d(3, 64, kernel_size=1)  # aligns input channels\n",
    "\n",
    "        # Block 2\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 1)\n",
    "        self.fc = nn.Linear(64 * 7 * 4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3, 30, 3)  # reshape input vector (270,) → (3, 30, 3)\n",
    "\n",
    "        # First residual connection\n",
    "        residual = self.shortcut1(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.relu(x + residual)\n",
    "        x = self.pool(x) # (64, 15, 3)\n",
    "\n",
    "        # Second residual connection (no need for shortcut: same shape)\n",
    "        residual = x\n",
    "        x = self.block2(x)\n",
    "        x = self.relu(x + residual)\n",
    "        x = self.pool(x) # (64, 7, 3)\n",
    "\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "512118c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PoseClassifierCNN(nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(PoseClassifierCNN, self).__init__()\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),  # (3, 30, 3) → (16, 30, 3)\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),  # (16, 15, 3)\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),  # (32, 15, 3)\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))  # (32, 7, 3)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),                    # (32 * 7 * 3)\n",
    "            nn.Linear(32 * 7 * 3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)     # output logits for 12 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input from (batch_size, 270) → (batch_size, 3, 30, 3)\n",
    "        x = x.view(-1, 3, 30, 3)  # match channel-first format\n",
    "        x = self.cnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b9187f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseClassifierFC(nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(PoseClassifierFC, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(270, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3c25571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated Learning Parameters\n",
    "NUM_CLIENTS = 10\n",
    "CLIENTS_PER_ROUND = 5\n",
    "FL_ROUNDS = 30\n",
    "\n",
    "# Local training parameters\n",
    "LOCAL_EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620735f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd13bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, X, y):\n",
    "    model.eval()\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_tensor)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        accuracy = ((preds == y_tensor).float().mean().item())*100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db3b88c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loss(model, X, y, criterion):\n",
    "    model.eval()\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_tensor)\n",
    "        loss = criterion(logits, y_tensor)\n",
    "    return loss.item()\n",
    "\n",
    "def weighted_train_loss(model_class, global_state, selected_clients, client_data, criterion):\n",
    "    train_losses = []\n",
    "    weights = []\n",
    "    for k in selected_clients:\n",
    "        model = model_class(num_classes=12)\n",
    "        model.load_state_dict(global_state)\n",
    "        loss = eval_loss(model, client_data[k]['X'], client_data[k]['y'], criterion)\n",
    "        train_losses.append(loss)\n",
    "        weights.append(len(client_data[k]['X']))\n",
    "    alpha = [w / sum(weights) for w in weights]\n",
    "    weighted_loss = sum(a * l for a, l in zip(alpha, train_losses))\n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8d4d3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "def initialize_global_model(model_class, num_classes=12):\n",
    "    \"\"\"Initialize the global model.\"\"\"\n",
    "    model = model_class(num_classes=num_classes)\n",
    "    return model, deepcopy(model.state_dict())\n",
    "\n",
    "def select_clients(client_ids, num_clients_per_round):\n",
    "    \"\"\"Randomly select a subset of clients for this round.\"\"\"\n",
    "    return random.sample(client_ids, num_clients_per_round)\n",
    "\n",
    "def local_train(model_class, global_state, client_dataset, local_epochs, batch_size, lr):\n",
    "    \"\"\"Train a local model on a client's data.\"\"\"\n",
    "    model = model_class(num_classes=12)\n",
    "    model.load_state_dict(global_state)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    X_local = torch.tensor(client_dataset['X'], dtype=torch.float32)\n",
    "    y_local = torch.tensor(client_dataset['y'], dtype=torch.long)\n",
    "    dataset = torch.utils.data.TensorDataset(X_local, y_local)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    for _ in range(local_epochs):\n",
    "        for xb, yb in loader:\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return deepcopy(model.state_dict()), len(X_local)\n",
    "\n",
    "def aggregate_models(local_states, local_sizes):\n",
    "    \"\"\"FedAvg aggregation of local model states.\"\"\"\n",
    "    total_samples = sum(local_sizes)\n",
    "    new_global_state = deepcopy(local_states[0])\n",
    "    for key in new_global_state:\n",
    "        new_global_state[key] = sum(\n",
    "            (local_states[i][key] * (local_sizes[i] / total_samples) for i in range(len(local_states)))\n",
    "        )\n",
    "    return new_global_state\n",
    "\n",
    "def federated_learning(\n",
    "    model_class, client_data, num_rounds, clients_per_round, local_epochs, batch_size, lr\n",
    "):\n",
    "    \"\"\"Main FL orchestrator loop.\"\"\"\n",
    "    client_ids = list(client_data.keys())\n",
    "    global_model, global_state = initialize_global_model(model_class)\n",
    "    for round_idx in range(num_rounds):\n",
    "        selected = select_clients(client_ids, clients_per_round)\n",
    "        local_states, local_sizes = [], []\n",
    "        for k in selected:\n",
    "            state, size = local_train(\n",
    "                model_class, global_state, client_data[k], local_epochs, batch_size, lr\n",
    "            )\n",
    "            local_states.append(state)\n",
    "            local_sizes.append(size)\n",
    "        global_state = aggregate_models(local_states, local_sizes)\n",
    "        global_model.load_state_dict(global_state)\n",
    "        print(f\"Round {round_idx+1}/{num_rounds} complete.\")\n",
    "\n",
    "        if (round_idx + 1) % 5 == 0:\n",
    "            # plot loss\n",
    "            train_accuracy = eval_model(global_model, X_test, y_test)\n",
    "            print(f\"Round {round_idx+1}: Test Accuracy = {train_accuracy:.4f} %\")\n",
    "            loss = weighted_train_loss(\n",
    "                model_class, global_state, selected, client_data, nn.CrossEntropyLoss()\n",
    "            )\n",
    "            print(f\"Round {round_idx+1}: Weighted Train Loss = {loss:.4f}\")\n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fcafb7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1/50 complete.\n",
      "Round 2/50 complete.\n",
      "Round 3/50 complete.\n",
      "Round 4/50 complete.\n",
      "Round 5/50 complete.\n",
      "Round 5: Test Accuracy = 0.3780 %\n",
      "Round 5: Weighted Train Loss = 1.1695\n",
      "Round 6/50 complete.\n",
      "Round 7/50 complete.\n",
      "Round 8/50 complete.\n",
      "Round 9/50 complete.\n",
      "Round 10/50 complete.\n",
      "Round 10: Test Accuracy = 0.4580 %\n",
      "Round 10: Weighted Train Loss = 0.7650\n",
      "Round 11/50 complete.\n",
      "Round 12/50 complete.\n",
      "Round 13/50 complete.\n",
      "Round 14/50 complete.\n",
      "Round 15/50 complete.\n",
      "Round 15: Test Accuracy = 0.4680 %\n",
      "Round 15: Weighted Train Loss = 0.7761\n",
      "Round 16/50 complete.\n",
      "Round 17/50 complete.\n",
      "Round 18/50 complete.\n",
      "Round 19/50 complete.\n",
      "Round 20/50 complete.\n",
      "Round 20: Test Accuracy = 0.4860 %\n",
      "Round 20: Weighted Train Loss = 0.5871\n",
      "Round 21/50 complete.\n",
      "Round 22/50 complete.\n",
      "Round 23/50 complete.\n",
      "Round 24/50 complete.\n",
      "Round 25/50 complete.\n",
      "Round 25: Test Accuracy = 0.5280 %\n",
      "Round 25: Weighted Train Loss = 0.4933\n",
      "Round 26/50 complete.\n",
      "Round 27/50 complete.\n",
      "Round 28/50 complete.\n",
      "Round 29/50 complete.\n",
      "Round 30/50 complete.\n",
      "Round 30: Test Accuracy = 0.5100 %\n",
      "Round 30: Weighted Train Loss = 0.4653\n",
      "Round 31/50 complete.\n",
      "Round 32/50 complete.\n",
      "Round 33/50 complete.\n",
      "Round 34/50 complete.\n",
      "Round 35/50 complete.\n",
      "Round 35: Test Accuracy = 0.5360 %\n",
      "Round 35: Weighted Train Loss = 0.3253\n",
      "Round 36/50 complete.\n",
      "Round 37/50 complete.\n",
      "Round 38/50 complete.\n",
      "Round 39/50 complete.\n",
      "Round 40/50 complete.\n",
      "Round 40: Test Accuracy = 0.5600 %\n",
      "Round 40: Weighted Train Loss = 0.4964\n",
      "Round 41/50 complete.\n",
      "Round 42/50 complete.\n",
      "Round 43/50 complete.\n",
      "Round 44/50 complete.\n",
      "Round 45/50 complete.\n",
      "Round 45: Test Accuracy = 0.5700 %\n",
      "Round 45: Weighted Train Loss = 0.4546\n",
      "Round 46/50 complete.\n",
      "Round 47/50 complete.\n",
      "Round 48/50 complete.\n",
      "Round 49/50 complete.\n",
      "Round 50/50 complete.\n",
      "Round 50: Test Accuracy = 0.5580 %\n",
      "Round 50: Weighted Train Loss = 0.1228\n",
      "Final Test Accuracy: 0.5580\n"
     ]
    }
   ],
   "source": [
    "# Federated Learning Hyperparameters\n",
    "NUM_CLIENTS = 10                # Number of clients participating in FL\n",
    "CLIENTS_PER_ROUND = 8         # Number of clients selected per FL round\n",
    "FL_ROUNDS = 50                 # Number of FL communication rounds\n",
    "LOCAL_EPOCHS = 10                # Number of local epochs per client per round\n",
    "BATCH_SIZE = 64                 # Batch size for local training\n",
    "LEARNING_RATE = 0.001           # Learning rate for local optimizer\n",
    "\n",
    "# Train the model using Federated Learning\n",
    "global_model = federated_learning(\n",
    "    model_class=PoseClassifierCNN,\n",
    "    client_data=client_data,\n",
    "    num_rounds=FL_ROUNDS,\n",
    "    clients_per_round=CLIENTS_PER_ROUND,\n",
    "    local_epochs=LOCAL_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    lr=LEARNING_RATE\n",
    ")\n",
    "\n",
    "# Evaluate the trained global model on the test set\n",
    "accuracy = eval_model(global_model, X_test, y_test)\n",
    "print(f\"Final Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bbc7939e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1/50 complete.\n",
      "Round 2/50 complete.\n",
      "Round 3/50 complete.\n",
      "Round 4/50 complete.\n",
      "Round 5/50 complete.\n",
      "Round 6/50 complete.\n",
      "Round 7/50 complete.\n",
      "Round 8/50 complete.\n",
      "Round 9/50 complete.\n",
      "Round 10/50 complete.\n",
      "Round 11/50 complete.\n",
      "Round 12/50 complete.\n",
      "Round 13/50 complete.\n",
      "Round 14/50 complete.\n",
      "Round 15/50 complete.\n",
      "Round 16/50 complete.\n",
      "Round 17/50 complete.\n",
      "Round 18/50 complete.\n",
      "Round 19/50 complete.\n",
      "Round 20/50 complete.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "# 1. Initialize a global ML model, ω(t = 0)\n",
    "global_model = PoseClassifierCNN(num_classes=12)\n",
    "global_model_state = deepcopy(global_model.state_dict())\n",
    "\n",
    "# Helper: get number of samples for each client\n",
    "client_num_samples = {k: len(client_data[k]['X']) for k in client_data}\n",
    "\n",
    "# Federated Learning Loop\n",
    "for round_idx in range(20):\n",
    "    # 2. Select a subset of clients S ⊆ K\n",
    "    selected_clients = random.sample(list(client_data.keys()), CLIENTS_PER_ROUND)\n",
    "    \n",
    "    local_states = []\n",
    "    local_sizes = []\n",
    "    \n",
    "    # 3. Send the global model to the clients, retrain locally\n",
    "    for k in selected_clients:\n",
    "        local_model = PoseClassifierCNN(num_classes=12)\n",
    "        local_model.load_state_dict(global_model_state)\n",
    "        local_model.train()\n",
    "        \n",
    "        optimizer = torch.optim.Adam(local_model.parameters(), lr=LEARNING_RATE)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        X_local = torch.tensor(client_data[k]['X'], dtype=torch.float32)\n",
    "        y_local = torch.tensor(client_data[k]['y'], dtype=torch.long)\n",
    "        \n",
    "        dataset = torch.utils.data.TensorDataset(X_local, y_local)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        \n",
    "        for epoch in range(LOCAL_EPOCHS):\n",
    "            for xb, yb in loader:\n",
    "                optimizer.zero_grad()\n",
    "                logits = local_model(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        # 4. Retrieve the individual models ωk(t)\n",
    "        local_states.append(deepcopy(local_model.state_dict()))\n",
    "        local_sizes.append(len(X_local))\n",
    "    \n",
    "    # 5. Aggregate the individual contributions (FedAvg)\n",
    "    total_samples = sum(local_sizes)\n",
    "    new_global_state = deepcopy(global_model_state)\n",
    "    for key in new_global_state:\n",
    "        new_global_state[key] = sum(\n",
    "            (local_states[i][key] * (local_sizes[i] / total_samples) for i in range(len(local_states)))\n",
    "        )\n",
    "    global_model_state = new_global_state\n",
    "    global_model.load_state_dict(global_model_state)\n",
    "    \n",
    "    print(f\"Round {round_idx+1}/{FL_ROUNDS} complete.\")\n",
    "\n",
    "# The trained global_model now contains the aggregated weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ce1593d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5280\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the global_model on the test set\n",
    "global_model.eval()\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = global_model(X_test_tensor)\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    accuracy = (preds == y_test_tensor).float().mean().item()\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
