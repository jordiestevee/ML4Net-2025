{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42bf4c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\jordi\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\jordi\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\jordi\\anaconda3\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jordi\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\jordi\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jordi\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jordi\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jordi\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jordi\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d87ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c453e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 270)\n",
      "(64,)\n",
      "(500, 270)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'dataset_Seminar5'\n",
    "num_clients = 10\n",
    "client_data = {}\n",
    "\n",
    "# Load each client’s training data\n",
    "for i in range(1, num_clients + 1):\n",
    "    X_path = os.path.join(data_dir, f'client_datasets/client_{i}_features.csv')\n",
    "    y_path = os.path.join(data_dir, f'client_datasets/client_{i}_labels.csv')\n",
    "    \n",
    "    X = pd.read_csv(X_path, header=None).values  # shape: (num_samples, 270)\n",
    "    y = pd.read_csv(y_path, header=None).values.flatten()  # shape: (num_samples,)\n",
    "    \n",
    "    client_data[i] = {'X': X, 'y': y}\n",
    "\n",
    "# Load test data\n",
    "X_test = pd.read_csv(os.path.join(data_dir, 'test_features.csv'), header=None).values\n",
    "y_test = pd.read_csv(os.path.join(data_dir, 'test_labels.csv'), header=None).values.flatten()\n",
    "\n",
    "print(X.shape)  # shape: (num_samples, 270)\n",
    "print(y.shape)  # shape: (num_samples,)\n",
    "print(X_test.shape)  # shape: (num_samples, 270)\n",
    "print(y_test.shape)  # shape: (num_samples,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b0c94",
   "metadata": {},
   "source": [
    "Chosen architecture: CNN (Ressim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd2ef4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for client_id in client_data:\n",
    "    client_data[client_id]['y'] -= 1  # Now ranges 0-11\n",
    "\n",
    "y_test -= 1  # Also adjust test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efedb4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResSim(nn.Module):\n",
    "    \"\"\"\n",
    "    A simplified ResNet-style network with residual connections and sequential blocks.\n",
    "    \n",
    "    Adapted for CSI input (flattened to 3x30x3).\n",
    "\n",
    "    Architecture:\n",
    "        - Two residual blocks: Conv → ReLU → Conv + skip\n",
    "        - Each followed by MaxPool\n",
    "        - Fully connected classifier\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): Number of output classes.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=12): # 12 different pose classes\n",
    "        super(ResSim, self).__init__()\n",
    "\n",
    "        # Block 1\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.shortcut1 = nn.Conv2d(3, 64, kernel_size=1)  # aligns input channels\n",
    "\n",
    "        # Block 2\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 1)\n",
    "        self.fc = nn.Linear(64 * 7 * 4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3, 30, 3)  # reshape input vector (270,) → (3, 30, 3)\n",
    "\n",
    "        # First residual connection\n",
    "        residual = self.shortcut1(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.relu(x + residual)\n",
    "        x = self.pool(x) # (64, 15, 3)\n",
    "\n",
    "        # Second residual connection (no need for shortcut: same shape)\n",
    "        residual = x\n",
    "        x = self.block2(x)\n",
    "        x = self.relu(x + residual)\n",
    "        x = self.pool(x) # (64, 7, 3)\n",
    "\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "512118c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PoseClassifierCNN(nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(PoseClassifierCNN, self).__init__()\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),  # (3, 30, 3) → (16, 30, 3)\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),  # (16, 15, 3)\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),  # (32, 15, 3)\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))  # (32, 7, 3)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),                    # (32 * 7 * 3)\n",
    "            nn.Linear(32 * 7 * 3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)     # output logits for 12 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input from (batch_size, 270) → (batch_size, 3, 30, 3)\n",
    "        x = x.view(-1, 3, 30, 3)  # match channel-first format\n",
    "        x = self.cnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "790e9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated Learning Parameters\n",
    "NUM_CLIENTS = 10\n",
    "CLIENTS_PER_ROUND = 5\n",
    "FL_ROUNDS = 30\n",
    "\n",
    "# Local training parameters\n",
    "LOCAL_EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b9187f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseClassifierFC(nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(PoseClassifierFC, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(270, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8178d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_train(model, X, y, epochs=LOCAL_EPOCHS, lr=LEARNING_RATE, batch_size=BATCH_SIZE):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(torch.FloatTensor(X), torch.LongTensor(y))\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for batch_X, batch_y in loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return model.state_dict(), len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71d17f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FL ROUND 1 ---\n",
      "\n",
      "--- FL ROUND 2 ---\n",
      "\n",
      "--- FL ROUND 3 ---\n",
      "\n",
      "--- FL ROUND 4 ---\n",
      "\n",
      "--- FL ROUND 5 ---\n",
      "\n",
      "--- FL ROUND 6 ---\n",
      "\n",
      "--- FL ROUND 7 ---\n",
      "\n",
      "--- FL ROUND 8 ---\n",
      "\n",
      "--- FL ROUND 9 ---\n",
      "\n",
      "--- FL ROUND 10 ---\n",
      "Test Accuracy: 22.20%\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Train the model federatedly\n",
    "global_model = federated_training(client_data, num_rounds=10, clients_per_round=5)\n",
    "\n",
    "# Step 2: Evaluate the global model\n",
    "evaluate(global_model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45de5a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def local_train(model, X, y, epochs=LOCAL_EPOCHS, lr=LEARNING_RATE, batch_size=BATCH_SIZE):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(torch.FloatTensor(X), torch.LongTensor(y))\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for batch_X, batch_y in loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return model.state_dict(), len(dataset)\n",
    "\n",
    "def fedavg(state_dicts, data_sizes):\n",
    "    global_model = state_dicts[0].copy()\n",
    "    total_size = sum(data_sizes)\n",
    "\n",
    "    for key in global_model.keys():\n",
    "        global_model[key] = sum(\n",
    "            state_dicts[i][key] * (data_sizes[i] / total_size)\n",
    "            for i in range(len(state_dicts))\n",
    "        )\n",
    "    return global_model\n",
    "\n",
    "def federated_training(client_data, rounds=FL_ROUNDS, clients_per_round=CLIENTS_PER_ROUND):\n",
    "    global_model = PoseClassifierFC()  # or PoseClassifierCNN()\n",
    "    global_state = global_model.state_dict()\n",
    "\n",
    "    for round_num in range(rounds):\n",
    "        print(f\"--- FL ROUND {round_num + 1} ---\")\n",
    "        selected = random.sample(list(client_data.keys()), clients_per_round)\n",
    "\n",
    "        local_states = []\n",
    "        local_sizes = []\n",
    "\n",
    "        for cid in selected:\n",
    "            local_model = PoseClassifierFC()\n",
    "            local_model.load_state_dict(global_state)\n",
    "            X = client_data[cid]['X']\n",
    "            y = client_data[cid]['y']\n",
    "            state, size = local_train(local_model, X, y)\n",
    "            local_states.append(state)\n",
    "            local_sizes.append(size)\n",
    "\n",
    "        global_state = fedavg(local_states, local_sizes)\n",
    "        global_model.load_state_dict(global_state)\n",
    "\n",
    "    return global_model\n",
    "\n",
    "def evaluate(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_tensor = torch.FloatTensor(X_test)\n",
    "        y_tensor = torch.LongTensor(y_test)\n",
    "        preds = model(X_tensor).argmax(dim=1)\n",
    "        acc = (preds == y_tensor).float().mean().item()\n",
    "    print(f\"\\n🎯 Test Accuracy: {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72c826ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FL ROUND 1 ---\n",
      "--- FL ROUND 2 ---\n",
      "--- FL ROUND 3 ---\n",
      "--- FL ROUND 4 ---\n",
      "--- FL ROUND 5 ---\n",
      "--- FL ROUND 6 ---\n",
      "--- FL ROUND 7 ---\n",
      "--- FL ROUND 8 ---\n",
      "--- FL ROUND 9 ---\n",
      "--- FL ROUND 10 ---\n",
      "--- FL ROUND 11 ---\n",
      "--- FL ROUND 12 ---\n",
      "--- FL ROUND 13 ---\n",
      "--- FL ROUND 14 ---\n",
      "--- FL ROUND 15 ---\n",
      "--- FL ROUND 16 ---\n",
      "--- FL ROUND 17 ---\n",
      "--- FL ROUND 18 ---\n",
      "--- FL ROUND 19 ---\n",
      "--- FL ROUND 20 ---\n",
      "--- FL ROUND 21 ---\n",
      "--- FL ROUND 22 ---\n",
      "--- FL ROUND 23 ---\n",
      "--- FL ROUND 24 ---\n",
      "--- FL ROUND 25 ---\n",
      "--- FL ROUND 26 ---\n",
      "--- FL ROUND 27 ---\n",
      "--- FL ROUND 28 ---\n",
      "--- FL ROUND 29 ---\n",
      "--- FL ROUND 30 ---\n",
      "\n",
      "🎯 Test Accuracy: 3.40%\n"
     ]
    }
   ],
   "source": [
    "# Train global model\n",
    "global_model = federated_training(client_data)\n",
    "\n",
    "# Evaluate on the shared test set\n",
    "evaluate(global_model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "971a61e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 labels: [ 0  3  4  5  6  8 10]\n",
      "Client 2 labels: [1 6]\n",
      "Client 3 labels: [ 1  3  7  8  9 10]\n",
      "Client 4 labels: [0 5 8]\n",
      "Client 5 labels: [2 5 7]\n",
      "Client 6 labels: [ 4  5 11]\n",
      "Client 7 labels: [ 0  3  4  7  8  9 10 11]\n",
      "Client 8 labels: [ 4  5  8 10]\n",
      "Client 9 labels: [ 0  1  5  7  8 10 11]\n",
      "Client 10 labels: [1 4 6]\n"
     ]
    }
   ],
   "source": [
    "for i, client in client_data.items():\n",
    "    print(f\"Client {i} labels:\", np.unique(client['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f84d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_training(client_data, test_data, model_cls, num_rounds=10, frac=0.5, local_epochs=1):\n",
    "    global_model = model_cls()\n",
    "    test_X, test_y = test_data\n",
    "\n",
    "    for round in range(num_rounds):\n",
    "        print(f\"--- Round {round+1} ---\")\n",
    "\n",
    "        # 1. Select random subset of clients\n",
    "        selected_clients = random.sample(list(client_data.keys()), int(frac * len(client_data)))\n",
    "\n",
    "        local_weights = []\n",
    "        local_sizes = []\n",
    "\n",
    "        # 2. Each client trains on its local data\n",
    "        for client_id in selected_clients:\n",
    "            data = client_data[client_id]\n",
    "            local_model = model_cls()\n",
    "            local_model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "            updated_weights = local_train(local_model, data['X'], data['y'], epochs=local_epochs)\n",
    "            local_weights.append(updated_weights)\n",
    "            local_sizes.append(len(data['y']))\n",
    "\n",
    "        # 3. Aggregate updates with FedAvg\n",
    "        averaged_weights = fed_avg(local_weights, local_sizes)\n",
    "        global_model.load_state_dict(averaged_weights)\n",
    "\n",
    "        # 4. Evaluate on test set\n",
    "        acc = evaluate(global_model, test_X, test_y)\n",
    "        print(f\"Test Accuracy after round {round+1}: {acc:.2f}%\")\n",
    "\n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ab1c7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Round 1 ---\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m final_model \u001b[38;5;241m=\u001b[39m federated_training(\n\u001b[0;32m      2\u001b[0m     client_data\u001b[38;5;241m=\u001b[39mclient_data,\n\u001b[0;32m      3\u001b[0m     test_data\u001b[38;5;241m=\u001b[39m(X_test, y_test),\n\u001b[0;32m      4\u001b[0m     model_cls\u001b[38;5;241m=\u001b[39mPoseClassifierCNN,\n\u001b[0;32m      5\u001b[0m     num_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      6\u001b[0m     frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,         \u001b[38;5;66;03m# 50% of clients per round\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     local_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n",
      "Cell \u001b[1;32mIn[37], line 25\u001b[0m, in \u001b[0;36mfederated_training\u001b[1;34m(client_data, test_data, model_cls, num_rounds, frac, local_epochs)\u001b[0m\n\u001b[0;32m     22\u001b[0m     local_sizes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# 3. Aggregate updates with FedAvg\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m averaged_weights \u001b[38;5;241m=\u001b[39m fed_avg(local_weights, local_sizes)\n\u001b[0;32m     26\u001b[0m global_model\u001b[38;5;241m.\u001b[39mload_state_dict(averaged_weights)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 4. Evaluate on test set\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 34\u001b[0m, in \u001b[0;36mfed_avg\u001b[1;34m(local_weights, local_sizes)\u001b[0m\n\u001b[0;32m     31\u001b[0m global_weights \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(local_weights[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     32\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(local_sizes)\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m global_weights\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     35\u001b[0m     global_weights[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\n\u001b[0;32m     36\u001b[0m         [local_weights[i][key] \u001b[38;5;241m*\u001b[39m (local_sizes[i] \u001b[38;5;241m/\u001b[39m total_samples)\n\u001b[0;32m     37\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(local_weights))]\n\u001b[0;32m     38\u001b[0m     )\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m global_weights\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "final_model = federated_training(\n",
    "    client_data=client_data,\n",
    "    test_data=(X_test, y_test),\n",
    "    model_cls=PoseClassifierCNN,\n",
    "    num_rounds=10,\n",
    "    frac=0.5,         # 50% of clients per round\n",
    "    local_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e21fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def create_dataloader(X: torch.Tensor, y: torch.Tensor, batch_size=32) -> torch.utils.data.DataLoader:\n",
    "    \"\"\"Converts client data to a DataLoader.\"\"\"\n",
    "    dataset = torch.utils.data.TensorDataset(X, y)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    X_test: torch.Tensor,\n",
    "    y_test: torch.Tensor,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Evaluates model on test data.\"\"\"\n",
    "    model.eval()\n",
    "    test_loader = create_dataloader(X_test, y_test, batch_size=64)\n",
    "    total_loss, correct = 0.0, 0\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            outputs = model(X)\n",
    "            total_loss += criterion(outputs, y).item()\n",
    "            correct += (outputs.argmax(1) == y).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / len(y_test)\n",
    "    return avg_loss, accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
