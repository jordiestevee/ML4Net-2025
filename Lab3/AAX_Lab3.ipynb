{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShbB8CxBMSLH"
      },
      "source": [
        "#ML4Net - Lab 3\n",
        "\n",
        "## Team members\n",
        "\n",
        "Name 1 (NIA 1) | Name 2 (NIA 2) | Name 3 (NIA 3)\n",
        "\n",
        "## Description\n",
        "\n",
        "In this lab, you will train a time series forecaster using Federated Learning (FL).\n",
        "\n",
        "The dataset you are going to use contains data from multiple APs. In particular, each AP's dataset contains the following features:\n",
        "\n",
        "* `datetime` is the timestamp (date) at which the measurement was taken\n",
        "* `Bytes` is the number of Bytes contributed at the corresponding datetime\n",
        "* `Active Connections` is the number of active connections (users connected to the AP) at the corresponding datetime\n",
        "* `Active Users` is the number of active users at the corresponding datetime\n",
        "* `AP ID` is the ID of the AP where the measurement was taken\n",
        "\n",
        "Original dataset: Chen, W., Lyu, F., Wu, F., Yang, P., & Ren, J. (2021). Flag: Flexible, accurate, and long-time user load prediction in large-scale WiFi system using deep RNN. IEEE Internet of Things Journal, 8(22), 16510-16521.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "*   Follow the steps from this Notebook and complete the proposed exercises.\n",
        "*   Deliver the completed Notebook by uploading it to your Github repository.\n",
        "*   **Submission deadline: 8 June 2025 (EoB).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqio72iAuxNJ"
      },
      "source": [
        "## Setting up the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VYfdaJF-qr5w"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset already exists: datasetLab3.pkl\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "dataset_url = \"https://github.com/fwilhelmi/fwilhelmi.github.io/raw/master/files/datasetLab3.pkl\"\n",
        "dataset_path = \"datasetLab3.pkl\"\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(\"Downloading dataset...\")\n",
        "    urllib.request.urlretrieve(dataset_url, dataset_path)\n",
        "    print(\"Download complete.\")\n",
        "else:\n",
        "    print(\"Dataset already exists:\", dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97kVtaWOutFD"
      },
      "source": [
        "## Loading the data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ-ATejy308z"
      },
      "source": [
        "Load the data from the pickle file (https://docs.python.org/3/library/pickle.html) that contains the dataset.\n",
        "\n",
        "**Important:** If you have issues with the dataset after automatically downloading and extracting it, download it and move it manually to the indicated folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Rn9zlRDcenHJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/mnt/c/Users/Marc/Documents/Uni/3r/3r Trimestre/MLNetworks/Labs/ML4Net-2025/Lab3\n",
            "True\n",
            "An error occurred: No module named 'numpy._core'\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "print(os.getcwd())\n",
        "print(os.path.exists('datasetLab3.pkl'))\n",
        "\n",
        "try:\n",
        "    with open('datasetLab3.pkl', 'rb') as f:\n",
        "        loaded_data = pickle.load(f)\n",
        "    print(\"Data loaded successfully:\")\n",
        "    print(loaded_data)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'datasetLab3.pkl' not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTAXUX5lN9KF"
      },
      "source": [
        "## EXERCISES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weqFFp6eShJg"
      },
      "source": [
        "### Exercise 1:\n",
        "\n",
        "Analyze the data from the different APs and discuss their properites (stationarity, trends, seasonality).\n",
        "\n",
        "Select 2 or 3 key APs showing different properties and generate:\n",
        "\n",
        "* Line plots (to plot the load vs the time)\n",
        "* Autocorrelation plots (to show the relationship between past and future samples of the load)\n",
        "* An Augmented Dickey-Fuller test (to study the stationarity of the AP)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "o3tirZCOSkNC"
      },
      "outputs": [],
      "source": [
        "# (response to exercise 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3vAU830SmuR"
      },
      "source": [
        "### Exercise 2:\n",
        "\n",
        "Prepare the data to be presented as a time series to the ML model. For that, you will have to split features from samples by differentiating between an observation window (e.g., 10 samples) and a prediction window (e.g., 2 samples). Use a sliding window to iterate over all the samples.\n",
        "\n",
        "Example: For an array [0,1,2,3,4,5], using an observation window $T_o$ = 3 and a prediction window $T_p$ = 1 would lead to the following time series data:\n",
        "* $x_1$ = [0,1,2], $y_1$ = [3]\n",
        "* $x_2$ = [1,2,3], $x_2$ = [4]\n",
        "* $x_3$ = [2,3,4], $y_3$ = [5]\n",
        "\n",
        "(where x are the features and y the labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PTjjIcWDS3yC"
      },
      "outputs": [],
      "source": [
        "# (response to exercise 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hgfWEriSpMa"
      },
      "source": [
        "### Exercise 3:\n",
        "\n",
        "Split the time series data into train, test, and validation, based on your criteria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PqgnnqflZ8R3"
      },
      "outputs": [],
      "source": [
        "# (response to exercise 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGXDiQQEZ5vL"
      },
      "source": [
        "### Exercise 4:\n",
        "Define a model (e.g., GRU, LSTM, CNN, Transformer) able to receive the time series the data you generated in the previous exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8AhYwVhNfWGA"
      },
      "outputs": [],
      "source": [
        "# (response to exercise 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy_SulYKeEn4"
      },
      "source": [
        "### Exercise 5:\n",
        "\n",
        "Train your model following two approaches:\n",
        "1. **Centralized model training:** Mix data from multiple APs to train the model in a centralized fashion.\n",
        "2. **Federated model training:** Consider APs as independent clients who contribute to training a global model by submitting local model updates.\n",
        "\n",
        "Show the results by calculating the following metrics from the de-normalized data:\n",
        "* Mean squared error (MSE)\n",
        "* Mean absolute error (MAE)\n",
        "* Mean absolute percentage error (MAPE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "TB4TAqiAeNXk"
      },
      "outputs": [],
      "source": [
        "# (response to exercise 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LafMStmKfW4-"
      },
      "source": [
        "###Â Exercise 6 (EXTRA):\n",
        "\n",
        "Reconsider your design to improve the accuracy of your model. For that, you can find a better approach to split the data (e.g., using larger observation windows) and include additional features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2Eb3K84dgTb1"
      },
      "outputs": [],
      "source": [
        "# (response to exercise 6)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "CompBioMed25",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
