{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ML4Net - Lab 2\n",
        "\n",
        "## Team members\n",
        "\n",
        "Name 1 (NIA 1) | Name 2 (NIA 2) | Name 3 (NIA 3)\n",
        "\n",
        "## Description\n",
        "\n",
        "In this lab, you will implement an ML model that detects congestion in Wi-Fi networks. In particular, you will desing and implement a supervised learning model (e.g., linear regression, multi-layer perceptron, neural network), which you will train using a dataset that was generated using the ns-3 simulator.\n",
        "\n",
        "Each row in the dataset is organized as (x1, x2, ..., x26, y1, y2, ..., y26, s, r, l), where:\n",
        "\n",
        "* `x1, x2..., x26, y1, y2, ..., y26` represent the histogram of the Inter-Frame Space (IFS) values for M frames that accessed the medium in a 60 seconds observation sample.\n",
        "  * `x26` represents the maximum IFS duration (in ms) in the considered M frames whereas `x1` is `x26`/26\n",
        "  * The remaining `xi` values are buckets at uniform spacing between `x1` and `x26`.\n",
        "  * For i>1, the values of `yi` represent the IFS histogram count (in percentage) for a corresponding bucket interval between `xi`-1 and `xi`.\n",
        "  * In the case of `y1`, the bucket interval is between 0 and `x1`\n",
        "* `s` is the average IFS duration (in ms)\n",
        "* `r` is the percentage of frame collisions\n",
        "* `l` is the label, where 1 indicates that the network is saturated, and 0, that it is not\n",
        "\n",
        "Original dataset: https://ieee-dataport.org/documents/dataset-identification-saturated-and-unsaturated-wi-fi-networks\n",
        "\n",
        "## Instructions\n",
        "\n",
        "*   Follow the steps from this Notebook and complete the proposed exercises.\n",
        "*   Deliver the completed Notebook by uploading it to your Github repository.\n",
        "*   Submission deadline: 1 June 2025 (EoB)."
      ],
      "metadata": {
        "id": "ShbB8CxBMSLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the environment"
      ],
      "metadata": {
        "id": "Lqio72iAuxNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Connect your Google Drive"
      ],
      "metadata": {
        "id": "hfR6f_lHpklt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Nl_xYKv2oYRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Download the dataset"
      ],
      "metadata": {
        "id": "RQxCHlkswbru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/fwilhelmi/fwilhelmi.github.io/raw/refs/heads/master/files/dataset_Lab2.zip"
      ],
      "metadata": {
        "id": "o6I9dNnpwbUB",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define the main path of the code"
      ],
      "metadata": {
        "id": "-5ZtSumzuZCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mypath=\"drive/MyDrive/AAX/Lab2\""
      ],
      "metadata": {
        "id": "VYfdaJF-qr5w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Extract the source code to the destination folder"
      ],
      "metadata": {
        "id": "ISnLhobTwh7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir $mypath; cp dataset_Lab2.zip $mypath; cd $mypath; unzip dataset_Lab2.zip"
      ],
      "metadata": {
        "id": "rgEgC4fZwiLf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "97kVtaWOutFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def plot_ifs_histogram(data_row):\n",
        "    \"\"\"\n",
        "    Plots the Inter-Frame Space (IFS) histogram from a single row of the dataset.\n",
        "\n",
        "    Args:\n",
        "        data_row (list or numpy.ndarray): A list or array representing a single row\n",
        "                                          in the format (x1, ..., x26, y1, ..., y26, s, r, l).\n",
        "    \"\"\"\n",
        "\n",
        "    # Get IFS values and the corresponding counts\n",
        "    x_values = np.array(data_row[:26])\n",
        "    y_counts = np.array(data_row[26:52])\n",
        "\n",
        "    # Calculate the bin edges based on x_values\n",
        "    bin_edges = [0] + list(x_values)\n",
        "\n",
        "    # Create the histogram plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(bin_edges[:-1], y_counts, width=np.diff(bin_edges)[0], align='edge', alpha=0.7)\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel(\"IFS Duration (ms)\")\n",
        "    plt.ylabel(\"Counts\")\n",
        "    plt.title(\"Inter-Frame Space (IFS) Histogram\")\n",
        "    plt.grid(axis='y', linestyle='--')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "\n",
        "# -> Read the data file\n",
        "file_name = mypath + '/train_data.csv'\n",
        "train_data_df = pd.read_csv(file_name, header=None)\n",
        "print(train_data_df.head())\n",
        "\n",
        "# -> Get a sample from the dataset and plot it\n",
        "row_index = 1\n",
        "sample_data = train_data_df.iloc[row_index].values\n",
        "plot_ifs_histogram(sample_data)"
      ],
      "metadata": {
        "id": "Rn9zlRDcenHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXERCISES"
      ],
      "metadata": {
        "id": "bTAXUX5lN9KF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1:\n",
        "Define an approach for training and validating the model you are going to train with the proposed data. Then, perform the split accordingly."
      ],
      "metadata": {
        "id": "weqFFp6eShJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (response to exercise 1)"
      ],
      "metadata": {
        "id": "o3tirZCOSkNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 2:\n",
        "\n",
        "Define your ML model, so that it can be called for training and test. Examples of approaches that you could use (but not limited to):\n",
        "\n",
        "*   Logistic Regression\n",
        "*   K-Nearest Neighbors (KNN)\n",
        "*   Decision Trees or Random Forests\n",
        "*   Convolutional Neural Network (CNN)"
      ],
      "metadata": {
        "id": "E3vAU830SmuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (response to exercise 2)"
      ],
      "metadata": {
        "id": "PTjjIcWDS3yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 3:\n",
        "\n",
        "Define the hyperparameters that you will use to train the model."
      ],
      "metadata": {
        "id": "7hgfWEriSpMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (response to exercise 3)"
      ],
      "metadata": {
        "id": "PqgnnqflZ8R3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 4:\n",
        "Train the model and show the procedure (e.g., evolution of the training/validation loss)."
      ],
      "metadata": {
        "id": "zGXDiQQEZ5vL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (response to exercise 4)"
      ],
      "metadata": {
        "id": "8AhYwVhNfWGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 5:\n",
        "\n",
        "Select and define the most appropriate evaluation metric(s). Discuss the appropriateness of your evaluation metrics for the binary classification problem we are considering."
      ],
      "metadata": {
        "id": "Uy_SulYKeEn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (response to exercise 5)"
      ],
      "metadata": {
        "id": "TB4TAqiAeNXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Â Exercise 6:\n",
        "\n",
        "Evaluate your trained model on the test set, using the evaluation metrics that you have proposed. Remember that the test data should have not been seen by the model, so that we can properly estimate of its generalization capabilities."
      ],
      "metadata": {
        "id": "LafMStmKfW4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (response to exercise 6)"
      ],
      "metadata": {
        "id": "2Eb3K84dgTb1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}